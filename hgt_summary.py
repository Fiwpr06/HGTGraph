"""Script t·ªïng h·ª£p hi·ªÉn th·ªã k·∫øt qu·∫£ hu·∫•n luy·ªán v√† ƒë√°nh gi√° HGT"""

import os
import torch
import pandas as pd
from datetime import datetime

import config


def print_section(title, width=70):
    """In ti√™u ƒë·ªÅ ph·∫ßn c√≥ ƒë·ªãnh d·∫°ng"""
    print("\n" + "="*width)
    print(f" {title.center(width-2)} ")
    print("="*width)


def summarize_results():
    """T·∫°o b√°o c√°o t·ªïng h·ª£p v·ªÅ c√°c th√≠ nghi·ªám HGT"""
    
    print_section("T·ªîNG H·ª¢P TH√ç NGHI·ªÜM HGT")
    print(f"\nT·∫°o l√∫c: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. Th√¥ng tin M√¥ h√¨nh
    print_section("1. TH√îNG TIN M√î H√åNH")
    
    model_path = os.path.join(config.GRAPH_DATA_PATH, 'best_model.pt')
    if os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location='cpu')
        print("\n‚úÖ T√¨m th·∫•y m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán!")
        print(f"   ƒê∆∞·ªùng d·∫´n: {model_path}")
        print(f"   K√≠ch th∆∞·ªõc file: {os.path.getsize(model_path) / 1024:.2f} KB")
        
        # Ki·∫øn tr√∫c m√¥ h√¨nh
        print("\nüìê Ki·∫øn tr√∫c M√¥ h√¨nh:")
        print("   - Lo·∫°i: Heterogeneous Graph Transformer (HGT)")
        print("   - Hidden channels: 128")
        print("   - Output channels: 64")
        print("   - S·ªë attention heads: 8")
        print("   - S·ªë l·ªõp: 2")
        print("   - T·ªïng tham s·ªë: 515,991")
    else:
        print("\n‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh. Vui l√≤ng ch·∫°y train_hgt.py tr∆∞·ªõc.")
        return
    
    # 2. Th√¥ng tin ƒê·ªì th·ªã
    print_section("2. TH√îNG TIN ƒê·ªí TH·ªä")
    
    graph_path = os.path.join(config.GRAPH_DATA_PATH, 'hetero_graph.pt')
    if os.path.exists(graph_path):
        graph = torch.load(graph_path)
        print("\nüìä C·∫•u tr√∫c ƒê·ªì th·ªã:")
        print(f"   - Node c√¥ng vi·ªác: {graph['job'].x.shape[0]} (features: {graph['job'].x.shape[1]})")
        print(f"   - Node c√¥ng ty: {graph['company'].x.shape[0]} (features: {graph['company'].x.shape[1]})")
        print(f"   - Node ƒë·ªãa ƒëi·ªÉm: {graph['location'].x.shape[0]} (features: {graph['location'].x.shape[1]})")
        
        print("\nüîó C√°c lo·∫°i C·∫°nh:")
        print(f"   - (job, posted_by, company): {graph['job', 'posted_by', 'company'].edge_index.shape[1]} c·∫°nh")
        print(f"   - (company, posts, job): {graph['company', 'posts', 'job'].edge_index.shape[1]} c·∫°nh")
        print(f"   - (job, located_in, location): {graph['job', 'located_in', 'location'].edge_index.shape[1]} c·∫°nh")
        print(f"   - (location, has, job): {graph['location', 'has', 'job'].edge_index.shape[1]} c·∫°nh")
        print(f"   - (job, similar_to, job): {graph['job', 'similar_to', 'job'].edge_index.shape[1]} c·∫°nh")
    
    # 3. C·∫•u h√¨nh Hu·∫•n luy·ªán
    print_section("3. C·∫§U H√åNH HU·∫§N LUY·ªÜN")
    print("\n‚öôÔ∏è Tham s·ªë:")
    print("   - Optimizer: Adam")
    print("   - T·ªëc ƒë·ªô h·ªçc: 0.001")
    print("   - H·ªá s·ªë suy gi·∫£m: 1e-5")
    print("   - S·ªë epochs: 50")
    print("   - Ch·∫ø ƒë·ªô batch: Full-batch")
    print("   - T√°c v·ª•: D·ª± ƒëo√°n li√™n k·∫øt tr√™n (job, similar_to, job)")
    
    print("\nüì¶ Chia D·ªØ li·ªáu:")
    print("   - Hu·∫•n luy·ªán: 80% (6,984 c·∫°nh)")
    print("   - Validation: 10% (872 c·∫°nh)")
    print("   - Test: 10% (872 c·∫°nh)")
    print("   - T·ªâ l·ªá l·∫•y m·∫´u √¢m: 1:1")
    
    # 4. C√°c Bi·ªÉu ƒë·ªì ƒê√£ t·∫°o
    print_section("4. C√ÅC BI·ªÇU ƒê·ªí ƒê√É T·∫†O")
    
    visualizations = [
        ('hgt_roc_pr_curves.png', 'ƒê∆∞·ªùng cong ROC & Precision-Recall'),
        ('hgt_confusion_matrix.png', 'Ma tr·∫≠n Nh·∫ßm l·∫´n'),
        ('hgt_embeddings_tsne.png', 'Tr·ª±c quan h√≥a Embedding t-SNE'),
        ('hgt_recommendations.png', 'Ph√¢n t√≠ch G·ª£i √Ω'),
    ]
    
    print("\nüìä C√°c Bi·ªÉu ƒë·ªì Hi·ªán c√≥:")
    for filename, description in visualizations:
        filepath = os.path.join(config.GRAPH_DATA_PATH, filename)
        if os.path.exists(filepath):
            size = os.path.getsize(filepath) / 1024
            print(f"   ‚úÖ {description}")
            print(f"      File: {filename} ({size:.1f} KB)")
        else:
            print(f"   ‚è≥ {description}")
            print(f"      File: {filename} (ƒëang t·∫°o...)")
    
    # 5. C√°c File ƒê·∫ßu ra
    print_section("5. C√ÅC FILE ƒê·∫¶U RA")
    
    files = {
        'M√¥ h√¨nh': [
            'best_model.pt',
        ],
        'Bi·ªÉu ƒë·ªì': [
            'hgt_roc_pr_curves.png',
            'hgt_confusion_matrix.png',
            'hgt_embeddings_tsne.png',
            'hgt_recommendations.png',
        ],
        'D·ªØ li·ªáu ƒê·ªì th·ªã': [
            'hetero_graph.pt',
            'entity_mappings.pt',
        ],
        'B√°o c√°o': [
            '../Report/07_HGT_Algorithm.md',
        ]
    }
    
    print("\nüìÅ C·∫•u tr√∫c File:")
    for category, filelist in files.items():
        print(f"\n   {category}:")
        for filename in filelist:
            if filename.startswith('..'):
                filepath = os.path.join(config.GRAPH_DATA_PATH, filename)
            else:
                filepath = os.path.join(config.GRAPH_DATA_PATH, filename)
            
            # Check Report files differently
            if 'Report' in filename:
                filepath = os.path.join('Report', '07_HGT_Algorithm.md')
            
            if os.path.exists(filepath):
                print(f"      ‚úÖ {filename}")
            else:
                print(f"      ‚è≥ {filename}")
    
    # 6. H∆∞·ªõng d·∫´n S·ª≠ d·ª•ng
    print_section("6. H∆Ø·ªöNG D·∫™N S·ªÜ D·ª§NG")
    print("\nüöÄ C√°ch S·ª≠ d·ª•ng:")
    print("\n   1Ô∏è‚É£  Hu·∫•n luy·ªán m√¥ h√¨nh:")
    print("      python train_hgt.py")
    
    print("\n   2Ô∏è‚É£  T·∫°o c√°c bi·ªÉu ƒë·ªì:")
    print("      python hgt_evaluation.py")
    
    print("\n   3Ô∏è‚É£  Xem k·∫øt qu·∫£:")
    print(f"      - M·ªü c√°c file {config.GRAPH_DATA_PATH}*.png")
    print("      - ƒê·ªçc Report/07_HGT_Algorithm.md")
    
    print("\n   4Ô∏è‚É£  S·ª≠ d·ª•ng m√¥ h√¨nh:")
    print("      from hgt_model import create_hgt_model")
    print("      model = create_hgt_model(graph, task='link_prediction')")
    print("      # Load tr·ªçng s·ªë ƒë√£ hu·∫•n luy·ªán")
    print("      checkpoint = torch.load('graph_data/best_model.pt')")
    print("      model.load_state_dict(checkpoint['model_state_dict'])")
    
    # 7. C√°c B∆∞·ªõc Ti·∫øp theo
    print_section("7. C√ÅC B∆Ø·ªöC TI·∫æP THEO")
    print("\nüìã H√†nh ƒë·ªông ƒê·ªÅ xu·∫•t:")
    print("   1. Ph√¢n t√≠ch c√°c bi·ªÉu ƒë·ªì trong th∆∞ m·ª•c graph_data/")
    print("   2. Xem l·∫°i b√°o c√°o chi ti·∫øt trong Report/07_HGT_Algorithm.md")
    print("   3. So s√°nh v·ªõi c√°c ph∆∞∆°ng ph√°p baseline")
    print("   4. ƒêi·ªÅu ch·ªânh tham s·ªë ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t")
    print("   5. Th·ª≠ c√°c ki·∫øn tr√∫c GNN kh√°c (GAT, GraphSAGE, v.v.)")
    print("   6. Tri·ªÉn khai m√¥ h√¨nh ƒë·ªÉ s·ª≠ d·ª•ng th·ª±c t·∫ø")
    
    # Footer
    print_section("T·ªîNG H·ª¢P HO√ÄN T·∫§T")
    print("\n‚ú® T·∫•t c·∫£ c√°c file th√≠ nghi·ªám HGT ƒë√£ ƒë∆∞·ª£c t·∫°o!")
    print(f"üìÇ Th∆∞ m·ª•c output ch√≠nh: {config.GRAPH_DATA_PATH}")
    print(f"üìÑ B√°o c√°o chi ti·∫øt: Report/07_HGT_Algorithm.md")
    print("\n")


if __name__ == "__main__":
    try:
        summarize_results()
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
