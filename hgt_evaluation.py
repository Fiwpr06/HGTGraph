"""C√¥ng c·ª• ƒë√°nh gi√° v√† tr·ª±c quan h√≥a cho m√¥ h√¨nh HGT"""

import os
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import torch
import torch.nn.functional as F
from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix
from sklearn.manifold import TSNE
import pandas as pd

import config
from hgt_model import create_hgt_model

sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10


class HGTEvaluator:
    """ƒê√°nh gi√° to√†n di·ªán v√† tr·ª±c quan h√≥a cho m√¥ h√¨nh HGT"""
    
    def __init__(self, model, graph, test_data, edge_type, device='cpu'):
        self.model = model.to(device)
        self.graph = graph
        self.test_data = test_data.to(device)
        self.edge_type = edge_type
        self.device = device
        
    @torch.no_grad()
    def get_predictions(self):
        """L·∫•y d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh tr√™n t·∫≠p test"""
        self.model.eval()
        
        edge_label_index = self.test_data[self.edge_type].edge_label_index
        edge_label = self.test_data[self.edge_type].edge_label
        
        x_dict = {
            'job': self.test_data['job'].x,
            'company': self.test_data['company'].x,
            'location': self.test_data['location'].x,
        }
        
        edge_index_dict = {
            key: self.test_data[key].edge_index
            for key in self.test_data.edge_types
        }
        
        pred = self.model(x_dict, edge_index_dict, edge_label_index, self.edge_type)
        pred_probs = torch.sigmoid(pred).cpu().numpy()
        labels = edge_label.cpu().numpy()
        
        return pred_probs, labels
    
    @torch.no_grad()
    def get_embeddings(self):
        """L·∫•y embeddings c·ªßa c√°c node t·ª´ HGT encoder"""
        self.model.eval()
        
        x_dict = {
            'job': self.graph['job'].x.to(self.device),
            'company': self.graph['company'].x.to(self.device),
            'location': self.graph['location'].x.to(self.device),
        }
        
        edge_index_dict = {
            ('job', 'posted_by', 'company'): self.graph['job', 'posted_by', 'company'].edge_index.to(self.device),
            ('company', 'posts', 'job'): self.graph['company', 'posts', 'job'].edge_index.to(self.device),
            ('job', 'located_in', 'location'): self.graph['job', 'located_in', 'location'].edge_index.to(self.device),
            ('location', 'has', 'job'): self.graph['location', 'has', 'job'].edge_index.to(self.device),
            ('job', 'similar_to', 'job'): self.graph['job', 'similar_to', 'job'].edge_index.to(self.device),
        }
        
        embeddings = self.model.encode(x_dict, edge_index_dict)
        
        # Chuy·ªÉn sang numpy
        embeddings_np = {
            key: emb.cpu().numpy() 
            for key, emb in embeddings.items()
        }
        
        return embeddings_np
    
    def plot_roc_pr_curves(self, save_path=None):
        """V·∫Ω ƒë∆∞·ªùng cong ROC v√† Precision-Recall"""
        pred_probs, labels = self.get_predictions()
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # ƒê∆∞·ªùng cong ROC
        fpr, tpr, _ = roc_curve(labels, pred_probs)
        from sklearn.metrics import roc_auc_score
        auc = roc_auc_score(labels, pred_probs)
        
        axes[0].plot(fpr, tpr, 'b-', linewidth=2, label=f'HGT (AUC = {auc:.4f})')
        axes[0].plot([0, 1], [0, 1], 'r--', linewidth=2, label='Ng·∫´u nhi√™n')
        axes[0].set_xlabel('T·ªâ l·ªá D∆∞∆°ng Gi·∫£ (FPR)', fontsize=12, fontweight='bold')
        axes[0].set_ylabel('T·ªâ l·ªá D∆∞∆°ng Th·ª±c (TPR)', fontsize=12, fontweight='bold')
        axes[0].set_title('ƒê∆∞·ªùng cong ROC - D·ª± ƒëo√°n Li√™n k·∫øt', fontsize=14, fontweight='bold')
        axes[0].legend(loc='lower right', fontsize=11)
        axes[0].grid(True, alpha=0.3)
        
        # ƒê∆∞·ªùng cong Precision-Recall
        precision, recall, _ = precision_recall_curve(labels, pred_probs)
        from sklearn.metrics import average_precision_score
        ap = average_precision_score(labels, pred_probs)
        
        axes[1].plot(recall, precision, 'b-', linewidth=2, label=f'HGT (AP = {ap:.4f})')
        axes[1].axhline(y=labels.mean(), color='r', linestyle='--', linewidth=2, label='Ng·∫´u nhi√™n')
        axes[1].set_xlabel('ƒê·ªô ph·ªß (Recall)', fontsize=12, fontweight='bold')
        axes[1].set_ylabel('ƒê·ªô ch√≠nh x√°c (Precision)', fontsize=12, fontweight='bold')
        axes[1].set_title('ƒê∆∞·ªùng cong Precision-Recall', fontsize=14, fontweight='bold')
        axes[1].legend(loc='lower left', fontsize=11)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"‚úÖ ƒê∆∞·ªùng cong ROC & PR ƒë√£ l∆∞u t·∫°i {save_path}")
        
        plt.close()
        
    def plot_confusion_matrix(self, threshold=0.5, save_path=None):
        """V·∫Ω ma tr·∫≠n nh·∫ßm l·∫´n (confusion matrix)"""
        pred_probs, labels = self.get_predictions()
        pred_labels = (pred_probs >= threshold).astype(int)
        
        cm = confusion_matrix(labels, pred_labels)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=['√Çm t√≠nh', 'D∆∞∆°ng t√≠nh'],
                    yticklabels=['√Çm t√≠nh', 'D∆∞∆°ng t√≠nh'],
                    cbar_kws={'label': 'S·ªë l∆∞·ª£ng'})
        plt.xlabel('Nh√£n d·ª± ƒëo√°n', fontsize=12, fontweight='bold')
        plt.ylabel('Nh√£n th·ª±c t·∫ø', fontsize=12, fontweight='bold')
        plt.title(f'Ma tr·∫≠n Nh·∫ßm l·∫´n (ng∆∞·ª°ng={threshold})', fontsize=14, fontweight='bold')
        
        # Th√™m c√°c ch·ªâ s·ªë
        tn, fp, fn, tp = cm.ravel()
        accuracy = (tp + tn) / (tp + tn + fp + fn)
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        metrics_text = f"ƒê·ªô ch√≠nh x√°c: {accuracy:.4f}\nPrecision: {precision:.4f}\nRecall: {recall:.4f}\nF1-Score: {f1:.4f}"
        plt.text(2.5, 0.5, metrics_text, fontsize=11, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"‚úÖ Ma tr·∫≠n nh·∫ßm l·∫´n ƒë√£ l∆∞u t·∫°i {save_path}")
        
        plt.close()
        
    def plot_embeddings_tsne(self, save_path=None):
        """Tr·ª±c quan h√≥a embeddings c·ªßa node b·∫±ng t-SNE"""
        embeddings = self.get_embeddings()
        
        # Load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω cho nh√£n
        df = pd.read_csv(f"{config.PROCESSED_DATA_PATH}jobs_processed.csv")
        
        fig, axes = plt.subplots(1, 2, figsize=(16, 7))
        
        # Bi·ªÉu ƒë·ªì 1: Embeddings c√¥ng vi·ªác theo danh m·ª•c
        job_embeddings = embeddings['job']
        
        print("ƒêang t√≠nh to√°n t-SNE cho embeddings c√¥ng vi·ªác...")
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        job_2d = tsne.fit_transform(job_embeddings)
        
        # Tr√≠ch xu·∫•t danh m·ª•c c√¥ng vi·ªác t·ª´ ti√™u ƒë·ªÅ
        def extract_category(title):
            title_lower = str(title).lower()
            # ƒê·ªãnh nghƒ©a c√°c danh m·ª•c
            if any(x in title_lower for x in ['developer', 'l·∫≠p tr√¨nh', 'it', 'software', 'backend', 'frontend', 'fullstack', 'k·ªπ s∆∞', 'engineer']):
                return 'IT/Developer'
            elif any(x in title_lower for x in ['k·∫ø to√°n', 'accountant', 'tax', 'thu·∫ø', 'finance', 't√†i ch√≠nh']):
                return 'Accounting/Finance'
            elif any(x in title_lower for x in ['sale', 'b√°n h√†ng', 'kinh doanh', 'marketing', 'market']):
                return 'Sales/Marketing'
            elif any(x in title_lower for x in ['hr', 'nh√¢n s·ª±', 'talent', 'recruitment', 'tuy·ªÉn d·ª•ng']):
                return 'HR/Recruitment'
            elif any(x in title_lower for x in ['thi·∫øt k·∫ø', 'design', 'ux', 'ui', 'ƒë·ªì h·ªça']):
                return 'Design'
            elif any(x in title_lower for x in ['t∆∞ v·∫•n', 'consultant', 'advisor', 'c·ªë v·∫•n']):
                return 'Consulting'
            elif any(x in title_lower for x in ['qu·∫£n l√Ω', 'manager', 'tr∆∞·ªüng ph√≤ng', 'gi√°m ƒë·ªëc', 'director']):
                return 'Management'
            elif any(x in title_lower for x in ['nh√¢n vi√™n', 'staff', 'chuy√™n vi√™n', 'specialist']):
                return 'Staff/Specialist'
            else:
                return 'Other'
        
        job_categories = df['Title'].apply(extract_category).values
        unique_categories = np.unique(job_categories)
        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_categories)))
        
        for i, category in enumerate(unique_categories):
            mask = job_categories == category
            axes[0].scatter(job_2d[mask, 0], job_2d[mask, 1], 
                          c=[colors[i]], label=category, alpha=0.6, s=50)
        
        axes[0].set_xlabel('Chi·ªÅu t-SNE 1', fontsize=12, fontweight='bold')
        axes[0].set_ylabel('Chi·ªÅu t-SNE 2', fontsize=12, fontweight='bold')
        axes[0].set_title('Embeddings C√¥ng vi·ªác (theo Danh m·ª•c)', fontsize=14, fontweight='bold')
        axes[0].legend(loc='best', fontsize=9)
        axes[0].grid(True, alpha=0.3)
        
        # Bi·ªÉu ƒë·ªì 2: Embeddings c√¥ng vi·ªác theo m·ª©c l∆∞∆°ng
        salary_avg = (df['salary_min'] + df['salary_max']) / 2
        scatter = axes[1].scatter(job_2d[:, 0], job_2d[:, 1], 
                                 c=salary_avg, cmap='viridis', alpha=0.6, s=50)
        
        axes[1].set_xlabel('Chi·ªÅu t-SNE 1', fontsize=12, fontweight='bold')
        axes[1].set_ylabel('Chi·ªÅu t-SNE 2', fontsize=12, fontweight='bold')
        axes[1].set_title('Embeddings C√¥ng vi·ªác (theo M·ª©c l∆∞∆°ng)', fontsize=14, fontweight='bold')
        cbar = plt.colorbar(scatter, ax=axes[1])
        cbar.set_label('M·ª©c l∆∞∆°ng TB (tri·ªáu VNƒê)', fontsize=10)
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"‚úÖ Tr·ª±c quan h√≥a embeddings ƒë√£ l∆∞u t·∫°i {save_path}")
        
        plt.close()
        
        # In th·ªëng k√™ danh m·ª•c
        print("\nüìä Ph√¢n b·ªë Danh m·ª•c C√¥ng vi·ªác:")
        category_counts = pd.Series(job_categories).value_counts()
        for cat, count in category_counts.items():
            percentage = (count / len(job_categories)) * 100
            print(f"   {cat:20s}: {count:3d} c√¥ng vi·ªác ({percentage:5.1f}%)")
        print(f"   {'='*40}")
        print(f"   {'T·ªïng':20s}: {len(job_categories):3d} c√¥ng vi·ªác")
        
        return job_categories
        
    def analyze_recommendations(self, job_idx=0, top_k=10, save_path=None):
        """Ph√¢n t√≠ch top-K g·ª£i √Ω cho m·ªôt c√¥ng vi·ªác c·ª• th·ªÉ"""
        embeddings = self.get_embeddings()
        job_embeddings = embeddings['job']
        
        # T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng
        target_emb = job_embeddings[job_idx]
        similarities = np.dot(job_embeddings, target_emb) / (
            np.linalg.norm(job_embeddings, axis=1) * np.linalg.norm(target_emb)
        )
        
        # L·∫•y top-K c√¥ng vi·ªác t∆∞∆°ng ƒë·ªìng nh·∫•t (kh√¥ng bao g·ªìm ch√≠nh n√≥)
        similarities[job_idx] = -1
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        # Load d·ªØ li·ªáu c√¥ng vi·ªác
        df = pd.read_csv(f"{config.PROCESSED_DATA_PATH}jobs_processed.csv")
        
        # T·∫°o bi·ªÉu ƒë·ªì tr·ª±c quan h√≥a
        fig, axes = plt.subplots(2, 1, figsize=(14, 10))
        
        # Bi·ªÉu ƒë·ªì tr√™n: Bi·ªÉu ƒë·ªì c·ªôt ƒë·ªô t∆∞∆°ng ƒë·ªìng
        top_sims = similarities[top_indices]
        job_titles = [df.iloc[i]['Title'][:30] for i in top_indices]
        
        axes[0].barh(range(top_k), top_sims, color='steelblue')
        axes[0].set_yticks(range(top_k))
        axes[0].set_yticklabels(job_titles, fontsize=9)
        axes[0].set_xlabel('ƒê·ªô t∆∞∆°ng ƒë·ªìng Cosine', fontsize=12, fontweight='bold')
        axes[0].set_title(f'Top-{top_k} C√¥ng vi·ªác T∆∞∆°ng ƒë·ªìng v·ªõi: {df.iloc[job_idx]["Title"][:50]}', 
                         fontsize=13, fontweight='bold')
        axes[0].invert_yaxis()
        axes[0].grid(True, alpha=0.3, axis='x')
        
        # Bi·ªÉu ƒë·ªì d∆∞·ªõi: So s√°nh ƒë·∫∑c tr∆∞ng
        target_job = df.iloc[job_idx]
        comparison_data = {
            'C√¥ng vi·ªác ƒê√≠ch': [
                target_job['salary_min'], 
                target_job['salary_max'],
                target_job['experience_years'],
                target_job['quantity']
            ]
        }
        
        for i, idx in enumerate(top_indices[:5]):  # Hi·ªÉn th·ªã top 5
            job = df.iloc[idx]
            comparison_data[f'T∆∞∆°ng ƒë·ªìng #{i+1}'] = [
                job['salary_min'],
                job['salary_max'],
                job['experience_years'],
                job['quantity']
            ]
        
        comparison_df = pd.DataFrame(comparison_data, 
                                     index=['L∆∞∆°ng T·ªëi thi·ªÉu', 'L∆∞∆°ng T·ªëi ƒëa', 'Kinh nghi·ªám (nƒÉm)', 'S·ªë l∆∞·ª£ng'])
        
        x = np.arange(len(comparison_df.index))
        width = 0.15
        
        for i, col in enumerate(comparison_df.columns):
            offset = width * (i - len(comparison_df.columns)/2 + 0.5)
            axes[1].bar(x + offset, comparison_df[col], width, label=col)
        
        axes[1].set_xlabel('ƒê·∫∑c tr∆∞ng', fontsize=12, fontweight='bold')
        axes[1].set_ylabel('Gi√° tr·ªã', fontsize=12, fontweight='bold')
        axes[1].set_title('So s√°nh ƒê·∫∑c tr∆∞ng', fontsize=13, fontweight='bold')
        axes[1].set_xticks(x)
        axes[1].set_xticklabels(comparison_df.index)
        axes[1].legend(loc='upper right', fontsize=9)
        axes[1].grid(True, alpha=0.3, axis='y')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"‚úÖ Ph√¢n t√≠ch g·ª£i √Ω ƒë√£ l∆∞u t·∫°i {save_path}")
        
        plt.close()
        
        return top_indices, similarities[top_indices]


def main():
    """ƒê√°nh gi√° to√†n di·ªán"""
    print("\n" + "="*70)
    print(" "*15 + "ƒê√ÅNH GI√Å & TR·ª∞C QUAN H√ìA M√î H√åNH HGT")
    print("="*70)
    
    # T·∫£i ƒë·ªì th·ªã v√† d·ªØ li·ªáu
    print("\n[1/6] ƒêang t·∫£i d·ªØ li·ªáu...")
    graph = torch.load(f"{config.GRAPH_DATA_PATH}hetero_graph.pt")
    
    # T·∫£i d·ªØ li·ªáu test (c·∫ßn t·∫°o l·∫°i split)
    from torch_geometric.transforms import RandomLinkSplit
    edge_type = ('job', 'similar_to', 'job')
    transform = RandomLinkSplit(
        num_val=0.1,
        num_test=0.1,
        edge_types=[edge_type],
        rev_edge_types=[edge_type],
        add_negative_train_samples=True,
        neg_sampling_ratio=1.0,
    )
    _, _, test_data = transform(graph)
    print("‚úÖ D·ªØ li·ªáu ƒë√£ t·∫£i")
    
    # T·∫£i m√¥ h√¨nh
    print("\n[2/6] ƒêang t·∫£i m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán...")
    from hgt_model import create_hgt_model
    model = create_hgt_model(graph, task='link_prediction', 
                            hidden_channels=128, out_channels=64, 
                            num_heads=8, num_layers=2)
    
    checkpoint = torch.load(f"{config.GRAPH_DATA_PATH}best_model.pt", map_location='cpu')
    model.load_state_dict(checkpoint['model_state_dict'])
    print("‚úÖ M√¥ h√¨nh ƒë√£ t·∫£i")
    
    # T·∫°o evaluator
    print("\n[3/6] ƒêang t·∫°o evaluator...")
    evaluator = HGTEvaluator(model, graph, test_data, edge_type, device='cpu')
    print("‚úÖ Evaluator ƒë√£ t·∫°o")
    
    # T·∫°o c√°c bi·ªÉu ƒë·ªì tr·ª±c quan
    print("\n[4/6] ƒêang t·∫°o ƒë∆∞·ªùng cong ROC & PR...")
    evaluator.plot_roc_pr_curves(save_path=f"{config.GRAPH_DATA_PATH}hgt_roc_pr_curves.png")
    
    print("\n[5/6] ƒêang t·∫°o ma tr·∫≠n nh·∫ßm l·∫´n...")
    evaluator.plot_confusion_matrix(save_path=f"{config.GRAPH_DATA_PATH}hgt_confusion_matrix.png")
    
    print("\n[6/6] ƒêang t·∫°o tr·ª±c quan embeddings...")
    evaluator.plot_embeddings_tsne(save_path=f"{config.GRAPH_DATA_PATH}hgt_embeddings_tsne.png")
    
    print("\n[7/7] ƒêang ph√¢n t√≠ch g·ª£i √Ω...")
    evaluator.analyze_recommendations(job_idx=0, top_k=10, 
                                     save_path=f"{config.GRAPH_DATA_PATH}hgt_recommendations.png")
    
    print("\n" + "="*70)
    print(" "*20 + "üéâ ƒê√ÅNH GI√Å HO√ÄN T·∫§T! üéâ")
    print("="*70)
    print(f"\nC√°c bi·ªÉu ƒë·ªì ƒë√£ t·∫°o:")
    print(f"  üìä {config.GRAPH_DATA_PATH}hgt_roc_pr_curves.png")
    print(f"  üìä {config.GRAPH_DATA_PATH}hgt_confusion_matrix.png")
    print(f"  üìä {config.GRAPH_DATA_PATH}hgt_embeddings_tsne.png")
    print(f"  üìä {config.GRAPH_DATA_PATH}hgt_recommendations.png")
    print("\n")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
