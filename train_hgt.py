"""Script huáº¥n luyá»‡n mÃ´ hÃ¬nh HGT cho tÃ¡c vá»¥ gá»£i Ã½ cÃ´ng viá»‡c"""

import os
import warnings
from typing import Dict, Tuple

import numpy as np
import torch
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score, average_precision_score
from torch_geometric.transforms import RandomLinkSplit

import config
from hgt_model import create_hgt_model

warnings.filterwarnings("ignore")


class HGTTrainer:
    """Lá»›p huáº¥n luyá»‡n mÃ´ hÃ¬nh HGT cho tÃ¡c vá»¥ dá»± Ä‘oÃ¡n liÃªn káº¿t"""

    def __init__(
        self,
        model,
        device='cuda' if torch.cuda.is_available() else 'cpu',
        lr=0.001,
        weight_decay=1e-5,
    ):
        """
        Tham sá»‘:
            model: MÃ´ hÃ¬nh HGT
            device: Thiáº¿t bá»‹ Ä‘á»ƒ huáº¥n luyá»‡n
            lr: Tá»‘c Ä‘á»™ há»c (learning rate)
            weight_decay: Há»‡ sá»‘ suy giáº£m trá»ng sá»‘
        """
        self.model = model.to(device)
        self.device = device

        self.optimizer = torch.optim.Adam(
            model.parameters(), lr=lr, weight_decay=weight_decay
        )

        print(f"\n{'='*60}")
        print(f"Khá»Ÿi táº¡o HGT Trainer")
        print(f"{'='*60}")
        print(f"Thiáº¿t bá»‹: {device}")
        print(f"Tá»‘c Ä‘á»™ há»c: {lr}")
        print(f"Há»‡ sá»‘ suy giáº£m: {weight_decay}")
        print(f"Sá»‘ tham sá»‘ mÃ´ hÃ¬nh: {sum(p.numel() for p in model.parameters()):,}")

    def train_epoch(self, data, edge_type):
        """Huáº¥n luyá»‡n má»™t epoch"""
        self.model.train()
        self.optimizer.zero_grad()

        data = data.to(self.device)

        # Láº¥y cÃ¡c cáº¡nh dÆ°Æ¡ng vÃ  Ã¢m
        edge_label_index = data[edge_type].edge_label_index
        edge_label = data[edge_type].edge_label

        # Lan truyá»n xuÃ´i
        x_dict = {
            'job': data['job'].x,
            'company': data['company'].x,
            'location': data['location'].x,
        }

        edge_index_dict = {
            key: data[key].edge_index
            for key in data.edge_types
        }

        pred = self.model(x_dict, edge_index_dict, edge_label_index, edge_type)

        # HÃ m máº¥t mÃ¡t binary cross entropy
        loss = F.binary_cross_entropy_with_logits(pred, edge_label.float())

        loss.backward()
        self.optimizer.step()

        return loss.item()

    @torch.no_grad()
    def evaluate(self, data, edge_type):
        """ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh"""
        self.model.eval()
        
        data = data.to(self.device)

        edge_label_index = data[edge_type].edge_label_index
        edge_label = data[edge_type].edge_label

        x_dict = {
            'job': data['job'].x,
            'company': data['company'].x,
            'location': data['location'].x,
        }

        edge_index_dict = {
            key: data[key].edge_index
            for key in data.edge_types
        }

        pred = self.model(x_dict, edge_index_dict, edge_label_index, edge_type)
        pred = torch.sigmoid(pred)

        preds = pred.cpu().numpy()
        labels = edge_label.cpu().numpy()

        # TÃ­nh cÃ¡c chá»‰ sá»‘
        auc = roc_auc_score(labels, preds)
        ap = average_precision_score(labels, preds)

        return auc, ap

    def train(
        self,
        train_data,
        val_data,
        test_data,
        edge_type,
        epochs=50,
        eval_every=5,
    ):
        """
        VÃ²ng láº·p huáº¥n luyá»‡n Ä‘áº§y Ä‘á»§

        Tham sá»‘:
            train_data: Dá»¯ liá»‡u huáº¥n luyá»‡n
            val_data: Dá»¯ liá»‡u validation
            test_data: Dá»¯ liá»‡u test
            edge_type: Loáº¡i cáº¡nh Ä‘á»ƒ dá»± Ä‘oÃ¡n
            epochs: Sá»‘ epoch
            eval_every: ÄÃ¡nh giÃ¡ sau má»—i N epochs
        """
        print(f"\n{'='*60}")
        print("Báº¯t Ä‘áº§u huáº¥n luyá»‡n")
        print(f"{'='*60}")
        print(f"Sá»‘ epochs: {epochs}")
        print(f"Loáº¡i cáº¡nh: {edge_type}"))

        best_val_auc = 0
        best_epoch = 0

        for epoch in range(1, epochs + 1):
            # Huáº¥n luyá»‡n
            loss = self.train_epoch(train_data, edge_type)

            # ÄÃ¡nh giÃ¡
            if epoch % eval_every == 0:
                train_auc, train_ap = self.evaluate(train_data, edge_type)
                val_auc, val_ap = self.evaluate(val_data, edge_type)

                print(f"\nEpoch {epoch:03d}:")
                print(f"  Máº¥t mÃ¡t: {loss:.4f}")
                print(f"  Huáº¥n luyá»‡n - AUC: {train_auc:.4f}, AP: {train_ap:.4f}")
                print(f"  Validation - AUC: {val_auc:.4f}, AP: {val_ap:.4f}")

                # LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t
                if val_auc > best_val_auc:
                    best_val_auc = val_auc
                    best_epoch = epoch
                    self.save_model('best_model.pt')
                    print(f"  âœ… MÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Ã£ Ä‘Æ°á»£c lÆ°u!")
            else:
                print(f"Epoch {epoch:03d}: Máº¥t mÃ¡t = {loss:.4f}")

        # Load mÃ´ hÃ¬nh tá»‘t nháº¥t vÃ  Ä‘Ã¡nh giÃ¡ trÃªn táº­p test
        print(f"\n{'='*60}")
        print("Huáº¥n luyá»‡n hoÃ n táº¥t!")
        print(f"{'='*60}")
        print(f"AUC validation tá»‘t nháº¥t: {best_val_auc:.4f} (Epoch {best_epoch})")

        self.load_model('best_model.pt')
        test_auc, test_ap = self.evaluate(test_data, edge_type)
        print(f"\nKáº¿t quáº£ Test cuá»‘i cÃ¹ng:")
        print(f"  AUC: {test_auc:.4f}")
        print(f"  AP:  {test_ap:.4f}")

        return {
            'best_val_auc': best_val_auc,
            'best_epoch': best_epoch,
            'test_auc': test_auc,
            'test_ap': test_ap,
        }

    def save_model(self, filename):
        """LÆ°u checkpoint cá»§a mÃ´ hÃ¬nh"""
        path = os.path.join(config.GRAPH_DATA_PATH, filename)
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
        }, path)

    def load_model(self, filename):
        """Táº£i checkpoint cá»§a mÃ´ hÃ¬nh"""
        path = os.path.join(config.GRAPH_DATA_PATH, filename)
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])


def prepare_data(graph, edge_type=('job', 'similar_to', 'job'), split_ratio=[0.8, 0.1, 0.1]):
    """
    Chuáº©n bá»‹ chia dá»¯ liá»‡u train/val/test

    Tham sá»‘:
        graph: Äá»‘i tÆ°á»£ng PyG HeteroData
        edge_type: Loáº¡i cáº¡nh dÃ¹ng cho dá»± Ä‘oÃ¡n liÃªn káº¿t
        split_ratio: Tá»‰ lá»‡ [train, val, test]

    Tráº£ vá»:
        train_data, val_data, test_data
    """
    print(f"\n{'='*60}")
    print("Chuáº©n bá»‹ dá»¯ liá»‡u")
    print(f"{'='*60}")
    print(f"Loáº¡i cáº¡nh cho dá»± Ä‘oÃ¡n: {edge_type}")
    print(f"Tá»‰ lá»‡ chia: Train={split_ratio[0]}, Val={split_ratio[1]}, Test={split_ratio[2]}")

    # Chia cÃ¡c cáº¡nh thÃ nh train/val/test
    transform = RandomLinkSplit(
        num_val=split_ratio[1],
        num_test=split_ratio[2],
        edge_types=[edge_type],
        rev_edge_types=[edge_type],  # VÃ¬ cÃ³ cáº¡nh hai chiá»u
        add_negative_train_samples=True,
        neg_sampling_ratio=1.0,  # Tá»‰ lá»‡ máº«u dÆ°Æ¡ng:máº«u Ã¢m = 1:1
    )

    train_data, val_data, test_data = transform(graph)

    print(f"\nChia dá»¯ liá»‡u hoÃ n táº¥t:")
    print(f"  Cáº¡nh train: {train_data[edge_type].edge_label_index.size(1)}")
    print(f"  Cáº¡nh val:   {val_data[edge_type].edge_label_index.size(1)}")
    print(f"  Cáº¡nh test:  {test_data[edge_type].edge_label_index.size(1)}")

    return train_data, val_data, test_data


def main():
    """Pipeline huáº¥n luyá»‡n chÃ­nh"""
    print("\n" + "="*70)
    print(" "*15 + "PIPELINE HUáº¤N LUYá»†N HGT")
    print("="*70)

    # Load Ä‘á»“ thá»‹
    print("\n[BÆ¯á»šC 1/4] Äang táº£i Ä‘á»“ thá»‹...")
    print("-"*70)
    graph_path = os.path.join(config.GRAPH_DATA_PATH, 'hetero_graph.pt')
    
    if not os.path.exists(graph_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file Ä‘á»“ thá»‹: {graph_path}")
        print("Vui lÃ²ng cháº¡y main.py trÆ°á»›c Ä‘á»ƒ xÃ¢y dá»±ng Ä‘á»“ thá»‹!")
        return
    
    graph = torch.load(graph_path)
    print(f"âœ… ÄÃ£ táº£i Ä‘á»“ thá»‹ tá»« {graph_path}")
    print(f"\nCáº¥u trÃºc Ä‘á»“ thá»‹:")
    print(graph)

    # Chuáº©n bá»‹ dá»¯ liá»‡u
    print("\n[BÆ¯á»šC 2/4] Äang chuáº©n bá»‹ dá»¯ liá»‡u...")
    print("-"*70)
    edge_type = ('job', 'similar_to', 'job')
    train_data, val_data, test_data = prepare_data(graph, edge_type)

    # Táº¡o mÃ´ hÃ¬nh
    print("\n[BÆ¯á»šC 3/4] Äang táº¡o mÃ´ hÃ¬nh...")
    print("-"*70)
    model = create_hgt_model(
        graph,
        task='link_prediction',
        hidden_channels=128,
        out_channels=64,
        num_heads=8,
        num_layers=2,
    )
    print(f"âœ… MÃ´ hÃ¬nh HGT Ä‘Ã£ Ä‘Æ°á»£c táº¡o")
    print(f"   Tham sá»‘: {sum(p.numel() for p in model.parameters()):,}")

    # Huáº¥n luyá»‡n
    print("\n[BÆ¯á»šC 4/4] Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh...")
    print("-"*70)
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    trainer = HGTTrainer(model, device=device, lr=0.001)
    
    results = trainer.train(
        train_data,
        val_data,
        test_data,
        edge_type,
        epochs=50,
        eval_every=5,
    )

    # TÃ³m táº¯t
    print("\n" + "="*70)
    print(" "*25 + "ğŸ‰ HUáº¤N LUYá»†N HOÃ€N Táº¤T! ğŸ‰")
    print("="*70)
    print("\nKáº¿t quáº£ cuá»‘i cÃ¹ng:")
    print(f"  AUC Validation tá»‘t nháº¥t: {results['best_val_auc']:.4f} (Epoch {results['best_epoch']})")
    print(f"  AUC Test:                {results['test_auc']:.4f}")
    print(f"  AP Test:                 {results['test_ap']:.4f}")
    print(f"\nMÃ´ hÃ¬nh Ä‘Ã£ lÆ°u táº¡i: {config.GRAPH_DATA_PATH}best_model.pt")
    print("\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Huáº¥n luyá»‡n bá»‹ ngáº¯t bá»Ÿi ngÆ°á»i dÃ¹ng")
    except Exception as e:
        print(f"\n\nâŒ Lá»—i xáº£y ra: {str(e)}")
        import traceback
        traceback.print_exc()
